{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test Cron\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,date,timedelta  \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dernier_jour.txt\", encoding=\"utf-8\")\n",
    "day = [word.strip() for word in f][-1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "day =pd.to_datetime('01-01-2016' , format=\"%d-%m-%Y\").date()\n",
    "f = open('dernier_jour.txt','a')\n",
    "f.write('\\n' + day.strftime('%d-%m-%Y'))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-01-01'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(day)  - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 2, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier = date.today() - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_monde(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    numero_page=1\n",
    "    e = False\n",
    "    liste_titre = []\n",
    "    while not e:\n",
    "        try:\n",
    "            \n",
    "            day_str = day.strftime('%d-%m-%Y')\n",
    "            url = \"https://www.lemonde.fr/archives-du-monde/\"+day_str+\"/\"+str(numero_page)+\"/\"\n",
    "            req = Request(url , headers=headers)\n",
    "            page = soup( urlopen(req).read() , \"lxml\")\n",
    "            for titre in page.find('section').findAll('h3',{ 'class':\"teaser__title\"}):\n",
    "                liste_titre.append(titre.getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' '))\n",
    "            numero_page +=1\n",
    "            \n",
    "        except Exception:\n",
    "            e=True\n",
    "            \n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_closer(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y/%m/%d')\n",
    "    url = \"https://www.closermag.fr/archives/\"+day_str\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    for titre in page.findAll('div',{ 'class':\"inner\"}):\n",
    "        liste_titre.append(titre.find('h2',{ 'class':\"title\"}).getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' '))\n",
    "\n",
    "        \n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_figaro(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y%m/%d')\n",
    "    url = \"https://articles.lefigaro.fr/\"+day_str+\"/\"\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    for titre in page.find('ul',{ 'class':\"list-group\"}).findAll('li',{'class':'list-group-item'}):\n",
    "        liste_titre.append(titre.getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' ').replace(\"\\n\", \"\"))\n",
    "        \n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_gorafi(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y/%m/%d/')\n",
    "    url = \"http://www.legorafi.fr/\"+day_str\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    for titre in page.find('div',{'class':'articles'}).findAll('h2'):\n",
    "        liste_titre.append(titre.getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' '))\n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_nord_presse(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y/%m/%d/')\n",
    "    url = \"https://nordpresse.be/\"+day_str\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    for titre in page.find('ul',{'class':'mvp-blog-story-list left relative infinite-content'}).findAll('h2'):\n",
    "        liste_titre.append(titre.getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' '))\n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_le_point(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%m-%Y/%d')\n",
    "    url = \"https://www.lepoint.fr/archives/\"+day_str+\".php\"\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    for titre in page.findAll('h2',{'class':'art-title'}):\n",
    "        liste_titre.append(titre.getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' ').strip())\n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_libe(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y/%m/%d')\n",
    "    numero_page = 1\n",
    "    vide = False\n",
    "    while not vide:\n",
    "        url = \"http://q.liberation.fr/archives/\"+day_str+\"/?page=\"+str(numero_page)\n",
    "        req = Request(url , headers=headers)\n",
    "        page = soup( urlopen(req).read() , \"lxml\")\n",
    "        if page.find('div',{ 'class':\"block-call-items\"}).findAll('p') :\n",
    "            for titre in page.find('div',{ 'class':\"block-call-items\"}).findAll('p'):\n",
    "                liste_titre.append(titre.find('a').getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' ').strip())\n",
    "            numero_page +=1\n",
    "        else:\n",
    "            vide=True\n",
    "        \n",
    "    return liste_titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-0a1a847f22d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[0mhier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mscrap_libe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-108-2eb3b009a66a>\u001b[0m in \u001b[0;36mscrap_libe\u001b[1;34m(day)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"block-call-items\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtitre\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"block-call-items\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mliste_titre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\xa0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "day = pd.to_datetime('01-02-2021' , format=\"%d-%m-%Y\").date()\n",
    "hier = date.today() - timedelta(days=1)\n",
    "\n",
    "while day!= hier:\n",
    "    day = day + timedelta(days=1)\n",
    "    scrap_libe(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-4f607acc2fb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"block-call-items\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtitre\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"block-call-items\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mliste_titre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\xa0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "liste_titre = []\n",
    "day_str = day.strftime('%Y/%m/%d')\n",
    "numero_page = 1\n",
    "vide = False\n",
    "while not vide:\n",
    "    url = \"http://q.liberation.fr/archives/\"+day_str+\"/?page=\"+str(numero_page)\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    if page.find('div',{ 'class':\"block-call-items\"}).findAll('p') :\n",
    "        for titre in page.find('div',{ 'class':\"block-call-items\"}).findAll('p'):\n",
    "            liste_titre.append(titre.find('a').getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' ').strip())\n",
    "        numero_page +=1\n",
    "    else:\n",
    "        vide=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.find('div',{ 'class':\"block-call-items\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_public(day) :\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y/%m/%d')\n",
    "    url = \"https://www.public.fr/Archives/liste/\"+day_str\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    for titre in page.findAll('a',{'class':'News-title News-title--small-onlymobile'}):\n",
    "        liste_titre.append(titre.get('title').strip())\n",
    "    return liste_titre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_sience_avenir(day):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre = []\n",
    "    day_str = day.strftime('%Y/%m/%d')\n",
    "    url = \"https://www.sciencesetavenir.fr/index/\"+day_str+\"/\"\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    liste_balise = page.find('div',{ 'class':\"bottom\"}).findAll('h2')\n",
    "    if liste_balise:\n",
    "        for titre in liste_balise:\n",
    "            liste_titre.append(titre.getText().strip())\n",
    "    return liste_titre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_charlie(day,tuple_listes):\n",
    "    \n",
    "    liste_titre = []\n",
    "    liste_th = []\n",
    "    for titre,date,th in zip (tuple_listes[0],tuple_listes[1],tuple_listes[2]):\n",
    "        if date==day:\n",
    "            liste_titre.append(titre)\n",
    "            liste_th.append(th)\n",
    "    return liste_titre,liste_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = ()\n",
    "if ll:\n",
    "    print('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recup_listes_charlie(day):\n",
    "    liste_titre = []\n",
    "    liste_date = []\n",
    "    liste_th = []\n",
    "    \n",
    "    liste_themes = ['politique','international','societe','ecologie','economie','sciences','culture','religions']\n",
    "    for theme in liste_themes: \n",
    "        liste_pages = []\n",
    "        numero_page=1\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "        last_day = day + timedelta(days=1) \n",
    "        \n",
    "        while day < last_day:\n",
    "            url = \"https://charliehebdo.fr/themes/\"+theme+'/page/'+str(numero_page)+'/'\n",
    "            req = Request(url , headers=headers)\n",
    "            page = soup( urlopen(req).read() , \"lxml\")\n",
    "            \n",
    "            dates = page.find('ul',{\"class\":'d-flex flex-row flex-wrap p-0 m-0'}).findAll('span',{'class':'ch_post_date content-block__author'})\n",
    "            last_day =  dateparser.parse(dates[-1].getText().strip()).date()\n",
    "            titres = page.find('ul',{\"class\":'d-flex flex-row flex-wrap p-0 m-0'}).findAll('h3')\n",
    "            \n",
    "            for titre,date in zip (titres,dates):\n",
    "                \n",
    "                liste_titre.append(titre.getText().encode('utf-8').decode('utf-8').replace(u'\\xa0', u' ').replace(u'\\u2009', u' '))\n",
    "                liste_date.append(dateparser.parse(date.getText().strip()).date())\n",
    "                liste_th.append(theme)\n",
    "            \n",
    "            #liste_pages.append(page)\n",
    "            \n",
    "            numero_page+=1\n",
    "        print(theme,numero_page-1)\n",
    "        #dic_theme[theme] = liste_pages\n",
    "    #return dic_theme\n",
    "    return liste_titre,liste_date,liste_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politique 1\n",
      "international 2\n",
      "societe 3\n",
      "ecologie 1\n",
      "economie 1\n",
      "sciences 1\n",
      "culture 1\n",
      "religions 1\n"
     ]
    }
   ],
   "source": [
    "aa = recup_pages_charlie(pd.to_datetime('10-01-2021' , format=\"%d-%m-%Y\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'politique',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'international',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'societe',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'ecologie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'economie',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'sciences',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'culture',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions',\n",
       " 'religions']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Gauche radicale : Alain Brossat et le professeur pyromane',\n",
       "  'Sans craie ni tableau noir'],\n",
       " ['societe', 'ecologie'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scrap_charlie(pd.to_datetime('10-01-2021' , format=\"%d-%m-%Y\"),aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politique\n",
      "international\n",
      "societe\n",
      "ecologie\n",
      "economie\n",
      "sciences\n",
      "culture\n",
      "religions\n"
     ]
    }
   ],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser\n",
    "def rech_date_art(day,theme):\n",
    "    np=0\n",
    "    #date article le plus vieux par catégorie\n",
    "    date_art_theme={'politique':pd.to_datetime('07-01-2015' , format=\"%d-%m-%Y\").date(),\n",
    "        'international':pd.to_datetime('06-04-2011' , format=\"%d-%m-%Y\").date(),\n",
    "        'societe':pd.to_datetime('05-03-2011' , format=\"%d-%m-%Y\").date(),\n",
    "        'ecologie':pd.to_datetime('07-01-2015' , format=\"%d-%m-%Y\").date(),\n",
    "        'economie':pd.to_datetime('07-01-2015' , format=\"%d-%m-%Y\").date(),\n",
    "        'sciences':pd.to_datetime('09-12-2015' , format=\"%d-%m-%Y\").date(),\n",
    "        'culture':pd.to_datetime('01-02-2017' , format=\"%d-%m-%Y\").date(),\n",
    "        'religions':pd.to_datetime('16-12-2015' , format=\"%d-%m-%Y\").date()}\n",
    "    if day<date_art_theme[theme]:\n",
    "        print(\"trop vieux\")\n",
    "        return None\n",
    "    \n",
    "    #check sur la première page (non nécessaire)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "    liste_titre=[]\n",
    "    #recherche sur première page et récupération nb pages \n",
    "    url = \"https://charliehebdo.fr/themes/\"+theme+'/page/1/'\n",
    "    req = Request(url , headers=headers)\n",
    "    page = soup( urlopen(req).read() , \"lxml\")\n",
    "    \n",
    "    nb_pages = int(page.find('ul',{ 'class':\"ch_pagination d-flex flex-row flex-wrap justify-content-end align-items-center text-right m-0 p-0\"}).find_all(lambda tag: tag.name == 'a' and tag.get('class') == ['page-numbers'])[-1].getText())\n",
    "    dates = page.find('ul',{\"class\":'d-flex flex-row flex-wrap p-0 m-0'}).findAll('span',{'class':'ch_post_date content-block__author'})\n",
    "    first_day = dateparser.parse(dates[0].getText().strip()).date()\n",
    "    last_day =  dateparser.parse(dates[-1].getText().strip()).date()\n",
    "    \n",
    "    if day > first_day:\n",
    "        #date du drnier article < date demandée\n",
    "        return None\n",
    "    elif first_day>=day>=last_day:\n",
    "        return 1\n",
    "    else:\n",
    "        mini=1\n",
    "        maxi=nb_pages\n",
    "        print(\"nb_pages\",nb_pages)\n",
    "        #recherche dicho\n",
    "        num_page_before = int\n",
    "        num_page = int((mini+maxi)//2)\n",
    "\n",
    "        while not ((first_day >= day >= last_day)  ) :\n",
    "            num_page_before = num_page\n",
    "            url = \"https://charliehebdo.fr/themes/\"+theme+'/page/'+str(num_page)+'/'\n",
    "            req = Request(url , headers=headers)\n",
    "            page = soup( urlopen(req).read() , \"lxml\")\n",
    "            dates = page.find('ul',{\"class\":'d-flex flex-row flex-wrap p-0 m-0'}).findAll('span',{'class':'ch_post_date content-block__author'})\n",
    "            first_day = dateparser.parse(dates[0].getText().strip()).date()\n",
    "            last_day =  dateparser.parse(dates[-1].getText().strip()).date()\n",
    "            if first_day < day:\n",
    "                print('debug',num_page)\n",
    "                maxi = num_page-1\n",
    "                num_page = int((mini+maxi)//2)\n",
    "                \n",
    "            elif last_day > day:\n",
    "                print('debuggg',num_page)\n",
    "                mini = num_page+1\n",
    "                num_page = int((mini+maxi)//2)\n",
    "            \n",
    "            if num_page == num_page_before:\n",
    "                #date entre deux pages\n",
    "                print('sortie!!',num_page)\n",
    "        return num_page\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"ch_post_date content-block__author\">le 4 février 2021</span>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://charliehebdo.fr/themes/politique/page/1/\"\n",
    "req = Request(url , headers=headers)\n",
    "page = soup( urlopen(req).read() , \"lxml\")\n",
    "\n",
    "#int(page.find('ul',{ 'class':\"ch_pagination d-flex flex-row flex-wrap justify-content-end align-items-center text-right m-0 p-0\"}).find_all(lambda tag: tag.name == 'a' and tag.get('class') == ['page-numbers'])[-1].getText())\n",
    "\n",
    "page.find('ul',{\"class\":'d-flex flex-row flex-wrap p-0 m-0'}).findAll('span',{'class':'ch_post_date content-block__author'})[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politique\n",
      "nb_pages 96\n",
      "debug 48\n",
      "debug 24\n",
      "debuggg 12\n",
      "debug 18\n",
      "debug 15\n",
      "debuggg 13\n",
      "debug 14\n",
      "debuggg 13\n",
      "sortie!! 13\n",
      "debuggg 13\n",
      "sortie!! 13\n",
      "debuggg 13\n",
      "sortie!! 13\n",
      "debuggg 13\n",
      "sortie!! 13\n",
      "debuggg 13\n",
      "sortie!! 13\n",
      "debuggg 13\n",
      "sortie!! 13\n",
      "debuggg 13\n",
      "sortie!! 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-2a77590b01aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mjour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'22-08-2019'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%d-%m-%Y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscrap_charlie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjour\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-485440eb13ae>\u001b[0m in \u001b[0;36mscrap_charlie\u001b[1;34m(day)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtheme\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mliste_themes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrech_date_art\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-d2dc410de246>\u001b[0m in \u001b[0;36mrech_date_art\u001b[1;34m(day, theme)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://charliehebdo.fr/themes/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtheme\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/page/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ul'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'd-flex flex-row flex-wrap p-0 m-0'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'ch_post_date content-block__author'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mfirst_day\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdateparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jour = pd.to_datetime('22-08-2019' , format=\"%d-%m-%Y\").date()\n",
    "scrap_charlie(jour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "48\n",
      "bbb\n",
      "24\n",
      "aaa\n",
      "36\n",
      "bbb\n",
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rech_date_art(pd.to_datetime('18-06-2018' , format=\"%d-%m-%Y\").date(),'politique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 1, 4)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "rech_date_art(day,'politique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Nombre mystère :  40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 est trop grand\n",
      "\n",
      "25 est trop petit\n",
      "\n",
      "37 est trop petit\n",
      "\n",
      "43 est trop grand\n",
      "\n",
      "Félicitations, vous avez trouvé le nombre mystère !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    " \n",
    "a = 0\n",
    " \n",
    "b = 100\n",
    " \n",
    "nb=0\n",
    " \n",
    "myst = int(input(\"Nombre mystère : \"))\n",
    " \n",
    "nb = int((a+b)//2)\n",
    " \n",
    "while nb != myst:\n",
    " \n",
    "    if myst < nb:\n",
    " \n",
    "        print(nb, \"est trop grand\\n\")\n",
    " \n",
    "        b=nb\n",
    " \n",
    "        nb = int((a+b)//2)\n",
    " \n",
    "    elif myst > nb:\n",
    " \n",
    "        print(nb, \"est trop petit\\n\")\n",
    " \n",
    "        a=nb\n",
    " \n",
    "        nb = int((a+b)//2)\n",
    " \n",
    "    if nb==myst:\n",
    " \n",
    "        print(\"Félicitations, vous avez trouvé le nombre mystère !\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recherche_dichotomique( element, liste_triee ):\n",
    "    a = 0\n",
    "    b = len(liste_triee)-1\n",
    "    m = (a+b)//2\n",
    "    while a < b :\n",
    "        if liste_triee[m] == element :\n",
    "            return m\n",
    "        elif liste_triee[m] > element :\n",
    "            b = m-1\n",
    "        else :\n",
    "            a = m+1\n",
    "        m = (a+b)//2\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Les kangourous communiquent avec nous grâce à leurs regards',\n",
       " 'USA: un déguisement gonflable a-t-il propagé le coronavirus dans un hôpital ?',\n",
       " \"Vaccin, mystère de Roanoke et rhinocéros laineux : l'actu des sciences\",\n",
       " \"Comment l'astrophysique s'est adaptée au Covid-19\",\n",
       " '\"Vaccin Covid\" : un téléservice pour se faire vacciner',\n",
       " 'Un bébé rhinocéros laineux incroyablement conservé retrouvé en Sibérie',\n",
       " \"Vaccins contre le Covid-19 : 35 Français tirés au sort dès aujourd'hui\",\n",
       " 'Covid-19 : en France, une stratégie vaccinale trop lente',\n",
       " \"Covid-19: le gouvernement tente d'éteindre les critiques sur le rythme de la vaccination\",\n",
       " 'ALERTE. Vaccination anti-Covid : \"réunion de suivi\" à l\\'Elysée lundi après-midi',\n",
       " \"Les émissions de CO2 du transport aérien ont suivi l'effondrement du trafic en 2020\",\n",
       " 'Le mystère de la \"Colonie perdue\" de Roanoke, premiers Anglais débarqués en Amérique, bientôt résolu ?',\n",
       " 'Covid-19 : que sait-on des deux nouveaux variants qui inquiètent ?',\n",
       " 'Norvège: cinq jours après un glissement de terrain, les recherches se poursuivent',\n",
       " \"Boris Johnson reconfine l'Angleterre\",\n",
       " \"DESSIN. L'œil de Lascar -  2021 meilleure que 2020 ?\",\n",
       " 'Vaccination: malgré les critiques, la HAS défend sa stratégie de cibler les Ehpad',\n",
       " 'Covid: vaccination à grande échelle à Pékin avant le Nouvel an chinois',\n",
       " 'Australie: un incendie menace des \"vies et des habitations\" près de Perth',\n",
       " 'Sommeil : ces pathologies qui gâchent nos nuits… et nos journées',\n",
       " 'Au Pakistan, le trafic de faucons alimenté par la demande des pays du Golfe',\n",
       " 'Japon: un nouvel état d\\'urgence est \"envisagé\" pour la région du grand Tokyo',\n",
       " \"Virus: l'Angleterre reconfinée, polémique en France sur la lenteur des vaccinations\"]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrap_sience_avenir(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if page.find('div',{ 'class':\"block-call-items\"}).findAll('p'):\n",
    "    print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-c8ad44f6978a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscrap_libe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-ac4e49935e26>\u001b[0m in \u001b[0;36mscrap_libe\u001b[1;34m(day)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"block-call-items\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtitre\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"block-call-items\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mliste_titre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\xa0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mnumero_page\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(self, name, attrs, recursive, text, **kwargs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m         criteria.\"\"\"\n\u001b[0;32m   1257\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrap_le_point(day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = day +timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On lit dernier jour de scrapp dans fichier text dans le current au format str et transfo au format date\n",
    "last_day_str = [word.strip() for word in open(\"dernier_jour.txt\", encoding=\"utf-8\")][-1] #str\n",
    "last_day = pd.to_datetime(last_day_str , format=\"%d-%m-%Y\").date() # si cron journalier => last_day == avant-hier\n",
    "day = last_day + timedelta(days=1)\n",
    "#dernier jour de scrapp == hier\n",
    "hier = date.today() - timedelta(days=1)\n",
    "\n",
    "#pour le scrapp\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "liste_titre = []\n",
    "liste_date = []\n",
    "           \n",
    "#on scrapp tant que jour != hier\n",
    "while day != hier :\n",
    "    #day = day + timedelta(days=1)\n",
    "    break\n",
    "    #le_monde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 1, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
